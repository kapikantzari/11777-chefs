\subsection{Qualitative Analysis and Examples}
% This section should likely contain a table of examples demonstrating how the current approach succeeds/fails.

We choose two videos, ``P26\_39" and ``P16\_04", to evaluate the models qualitatively. The ground truth segmentation of ``P26\_39" (\ref{fig:2639}) consists of segments of long-duration, whereas ``P16\_04" consists of a large number of very short segments. We can see that it is very challenging for FC to get the class label correctly, as it predicts the most common verb ``wash" (olive-green) instead of the ground truth ``mix" (hot pink). For videos with a few number of long segments, DGTRM tends to over-segment, possibly because of its more complicated architecture compared to the other models. However, the tendency to over-segment, or being very sensitive to visual changes in frames, helps it to handle videos with very short segments interleaved together, as in \ref{fig:1604}. The advantage of larger models like MSTCN and DGTRM over FC is clear from \ref{fig:baseline_qualitative}: both MSTCN and DGTRM have learned to predict the ground truth class and give more accurate segmentations. The over-segmentation issue of FC, which is much more severe than DGTRM, can be seen in \ref{fig:1604}.

